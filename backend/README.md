–ö–æ—Å–º–∏—á–µ—Å–∫–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è! üöÄ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —É–∂–µ –ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –¥–ª—è serverless –Ω–∞ Vercel. –î–∞–≤–∞–π —Ñ–∏–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–±–æ—á–∏–π –±—ç–∫–µ–Ω–¥ (TS-—Ñ—É–Ω–∫—Ü–∏–∏ –≤ /api) ‚Äî –¥–æ–±–∞–≤–ª—é –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–π —ç–Ω–¥–ø–æ–∏–Ω—Ç fix/apply.ts, –∞ —Ç–∞–∫–∂–µ –¥–∞–º –ø–æ–ª–Ω—ã–µ –≤–µ—Ä—Å–∏–∏ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤, —á—Ç–æ–±—ã –º–æ–∂–Ω–æ –±—ã–ª–æ –ø—Ä–æ—Å—Ç–æ –≤—Å—Ç–∞–≤–∏—Ç—å –∏ –¥–µ–ø–ª–æ–∏—Ç—å.

üìÅ –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ (serverless, Vercel)
backend/
‚îú‚îÄ api/
‚îÇ  ‚îú‚îÄ health.ts
‚îÇ  ‚îú‚îÄ ai/
‚îÇ  ‚îÇ  ‚îú‚îÄ analyze.ts
‚îÇ  ‚îÇ  ‚îú‚îÄ chat.ts
‚îÇ  ‚îÇ  ‚îî‚îÄ fix/
‚îÇ  ‚îÇ     ‚îî‚îÄ apply.ts
‚îú‚îÄ package.json
‚îî‚îÄ vercel.json

üß© –§–∞–π–ª—ã (—Å–∫–æ–ø–∏—Ä—É–π ¬´–∫–∞–∫ –µ—Å—Ç—å¬ª)
api/health.ts
import type { VercelRequest, VercelResponse } from '@vercel/node';

export default function handler(req: VercelRequest, res: VercelResponse) {
  res.setHeader('Cache-Control', 'no-store');
  res.status(200).json({
    status: 'OK',
    service: 'iCoder Plus Backend (serverless)',
    timestamp: new Date().toISOString(),
  });
}

api/ai/analyze.ts
import type { VercelRequest, VercelResponse } from '@vercel/node';
import OpenAI from 'openai';

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

type AnalysisType = 'review' | 'commit' | 'optimize';
interface Body {
  code?: string;
  oldCode?: string;
  fileName?: string;
  analysisType: AnalysisType;
}

export default async function handler(req: VercelRequest, res: VercelResponse) {
  res.setHeader('Access-Control-Allow-Origin', '*');
  res.setHeader('Access-Control-Allow-Methods', 'POST, OPTIONS');
  res.setHeader('Access-Control-Allow-Headers', 'Content-Type');

  if (req.method === 'OPTIONS') return res.status(200).end();
  if (req.method !== 'POST') return res.status(405).json({ error: 'Method Not Allowed' });

  try {
    const { code = '', oldCode = '', fileName = 'untitled', analysisType } = (req.body || {}) as Body;

    if (!process.env.OPENAI_API_KEY) {
      return res.status(200).json({ success: true, data: ['‚ö†Ô∏è OPENAI_API_KEY –Ω–µ –∑–∞–¥–∞–Ω ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞—é –∑–∞–≥–ª—É—à–∫—É'] });
    }
    if (!analysisType) return res.status(400).json({ error: 'analysisType is required' });

    let prompt = '';
    if (analysisType === 'review') {
      prompt = `–¢—ã ‚Äî –ª–∞–∫–æ–Ω–∏—á–Ω—ã–π code reviewer. –î–∞–π 2‚Äì4 –∫–æ—Ä–æ—Ç–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ (80c max, —Å —ç–º–æ–¥–∑–∏).
–§–∞–π–ª: ${fileName}
–ö–æ–¥:
\`\`\`
${code.slice(0, 12000)}
\`\`\`
–í–µ—Ä–Ω–∏ JSON-–º–∞—Å—Å–∏–≤ —Å—Ç—Ä–æ–∫ (["...", "..."]).`;
    } else if (analysisType === 'commit') {
      prompt = `–°—Ä–∞–≤–Ω–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è –∏ –¥–∞–π –û–î–ù–û –∫–æ—Ä–æ—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ, –Ω–∞—á–∏–Ω–∞—è —Å —ç–º–æ–¥–∑–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä "‚ú® –î–æ–±–∞–≤–ª–µ–Ω–æ ‚Ä¶").
–§–∞–π–ª: ${fileName}
OLD:
\`\`\`
${oldCode.slice(0, 6000)}
\`\`\`
NEW:
\`\`\`
${code.slice(0, 6000)}
\`\`\``;
    } else if (analysisType === 'optimize') {
      prompt = `–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∫–æ–¥ –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ 2‚Äì3 –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ (–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å/–ø–∞–º—è—Ç—å/–∞–ª–≥–æ—Ä–∏—Ç–º—ã).
–í–µ—Ä–Ω–∏ JSON-–º–∞—Å—Å–∏–≤ —Å—Ç—Ä–æ–∫ —Å —ç–º–æ–¥–∑–∏.
–ö–æ–¥:
\`\`\`
${code.slice(0, 12000)}
\`\`\``;
    } else {
      return res.status(400).json({ error: 'Unsupported analysisType' });
    }

    const ai = await openai.chat.completions.create({
      model: 'gpt-4o-mini',
      temperature: 0.2,
      max_tokens: 400,
      messages: [{ role: 'user', content: prompt }],
    });

    const content = ai.choices?.[0]?.message?.content?.trim() ?? '';
    let data: unknown = content;

    // –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON-–º–∞—Å—Å–∏–≤, –µ—Å–ª–∏ –ø—Ä–∏—Å–ª–∞–ª–∏
    if (analysisType !== 'commit') {
      try {
        const parsed = JSON.parse(content);
        if (Array.isArray(parsed)) data = parsed;
      } catch {
        /* ignore, –≤–µ—Ä–Ω—ë–º –∫–∞–∫ –µ—Å—Ç—å */
      }
    }

    return res.status(200).json({
      success: true,
      analysisType,
      fileName,
      data,
      timestamp: new Date().toISOString(),
    });
  } catch (err: any) {
    return res.status(500).json({ error: 'AI analyze failed', details: err?.message ?? String(err) });
  }
}

api/ai/chat.ts
import type { VercelRequest, VercelResponse } from '@vercel/node';
import OpenAI from 'openai';

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

interface Body {
  message: string;
  code?: string;
  fileName?: string;
}

export default async function handler(req: VercelRequest, res: VercelResponse) {
  res.setHeader('Access-Control-Allow-Origin', '*');
  res.setHeader('Access-Control-Allow-Methods', 'POST, OPTIONS');
  res.setHeader('Access-Control-Allow-Headers', 'Content-Type');

  if (req.method === 'OPTIONS') return res.status(200).end();
  if (req.method !== 'POST') return res.status(405).json({ error: 'Method Not Allowed' });

  try {
    const { message, code = '', fileName = 'untitled' } = (req.body || {}) as Body;

    if (!message) return res.status(400).json({ error: 'message is required' });
    if (!process.env.OPENAI_API_KEY) {
      return res.status(200).json({ success: true, data: { message: '‚ö†Ô∏è OPENAI_API_KEY –Ω–µ –∑–∞–¥–∞–Ω ‚Äî –∑–∞–≥–ª—É—à–∫–∞ –æ—Ç–≤–µ—Ç–∞' } });
    }

    const prompt = `–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç-–ø–æ–º–æ—â–Ω–∏–∫ IDE iCoder Plus. –û—Ç–≤–µ—Ç—å –∫—Ä–∞—Ç–∫–æ (<=150 —Å–ª–æ–≤).
–§–∞–π–ª: ${fileName}
–í–æ–ø—Ä–æ—Å: ${message}
–ö–æ–Ω—Ç–µ–∫—Å—Ç –∫–æ–¥–∞:
\`\`\`
${code.slice(0, 12000)}
\`\`\``;

    const ai = await openai.chat.completions.create({
      model: 'gpt-4o-mini',
      temperature: 0.4,
      max_tokens: 300,
      messages: [{ role: 'user', content: prompt }],
    });

    const reply = ai.choices?.[0]?.message?.content?.trim() ?? '–û—Ç–≤–µ—Ç –Ω–µ –ø–æ–ª—É—á–µ–Ω.';
    return res.status(200).json({
      success: true,
      data: {
        message: reply,
        conversationId: `conv_${Date.now()}`,
        timestamp: new Date().toISOString(),
      },
    });
  } catch (err: any) {
    return res.status(500).json({ error: 'AI chat failed', details: err?.message ?? String(err) });
  }
}

api/ai/fix/apply.ts
import type { VercelRequest, VercelResponse } from '@vercel/node';
import OpenAI from 'openai';

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

interface Body {
  code: string;
  fileName?: string;
}

export default async function handler(req: VercelRequest, res: VercelResponse) {
  res.setHeader('Access-Control-Allow-Origin', '*');
  res.setHeader('Access-Control-Allow-Methods', 'POST, OPTIONS');
  res.setHeader('Access-Control-Allow-Headers', 'Content-Type');

  if (req.method === 'OPTIONS') return res.status(200).end();
  if (req.method !== 'POST') return res.status(405).json({ error: 'Method Not Allowed' });

  try {
    const { code = '', fileName = 'untitled' } = (req.body || {}) as Body;
    if (!code) return res.status(400).json({ error: 'code is required' });

    // Fallback –±–µ–∑ –∫–ª—é—á–∞ ‚Äî –±–∞–∑–æ–≤—ã–µ —Ñ–∏–∫—Å—ã
    const basicFix = (src: string) =>
      src
        .replace(/\bvar\s+(\w+)/g, 'let $1')
        .replace(/console\.log\(.*?\);?/g, '')
        .split('\n')
        .map((l) => l.trimEnd())
        .join('\n')
        .trim();

    if (!process.env.OPENAI_API_KEY) {
      return res.status(200).json({
        success: true,
        data: {
          originalCode: code,
          fixedCode: basicFix(code),
          fileName,
          appliedAt: new Date().toISOString(),
          note: '‚ö†Ô∏è OPENAI_API_KEY –Ω–µ –∑–∞–¥–∞–Ω ‚Äî –ø—Ä–∏–º–µ–Ω–µ–Ω—ã –±–∞–∑–æ–≤—ã–µ —Ñ–∏–∫—Å—ã',
        },
      });
    }

    const prompt = `–û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–π –∏ –º–æ–¥–µ—Ä–Ω–∏–∑–∏—Ä—É–π –∫–æ–¥. 
–ü—Ä–∞–≤–∏–ª–∞:
1) –ó–∞–º–µ–Ω–∏ var –Ω–∞ let/const –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ
2) –£–¥–∞–ª–∏ console.log
3) –ò—Å–ø—Ä–∞–≤—å —á–∞—Å—Ç—ã–µ —Å–∏–Ω—Ç–∞–∫—Å. –æ–≥—Ä–µ—Ö–∏
4) –ú–æ–¥–µ—Ä–Ω–∏–∑–∏—Ä—É–π JS (arrow/–¥–µ—Å—Ç—Ä—É–∫—Ç—É—Ä–∏–∑–∞—Ü–∏—è –≥–¥–µ —É–º–µ—Å—Ç–Ω–æ)
5) –£–¥–∞–ª–∏ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –∏–º–ø–æ—Ä—Ç—ã
–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –≥–æ—Ç–æ–≤—ã–π –∫–æ–¥ (–±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π).

–§–∞–π–ª: ${fileName}
–ö–æ–¥:
\`\`\`
${code}
\`\`\``;

    const ai = await openai.chat.completions.create({
      model: 'gpt-4o-mini',
      temperature: 0.1,
      max_tokens: Math.min(2000, code.length + 600),
      messages: [{ role: 'user', content: prompt }],
    });

    const raw = ai.choices?.[0]?.message?.content ?? '';
    const fixed = raw.replace(/^```[\w-]*\s*/i, '').replace(/```$/i, '').trim();

    return res.status(200).json({
      success: true,
      data: {
        originalCode: code,
        fixedCode: fixed || basicFix(code),
        fileName,
        appliedAt: new Date().toISOString(),
      },
    });
  } catch (err: any) {
    return res.status(500).json({ error: 'AI fix failed', details: err?.message ?? String(err) });
  }
}

package.json
{
  "name": "icoder-plus-backend-serverless",
  "version": "2.0.0",
  "private": true,
  "description": "iCoder Plus ‚Äî serverless backend for Vercel",
  "scripts": {
    "dev": "vercel dev",
    "deploy": "vercel --prod"
  },
  "dependencies": {
    "openai": "^4.58.1"
  },
  "devDependencies": {
    "@vercel/node": "^3.2.12",
    "typescript": "^5.4.0"
  }
}

vercel.json
{
  "$schema": "https://openapi.vercel.sh/vercel.json",
  "functions": {
    "api/**/*.{ts,js}": {
      "runtime": "nodejs20.x",
      "memory": 512,
      "maxDuration": 15
    }
  },
  "routes": [
    { "src": "/api/(.*)", "dest": "/api/$1" }
  ]
}

üîë –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è (Vercel ‚Üí Settings ‚Üí Environment Variables)

–î–ª—è –ø—Ä–æ–µ–∫—Ç–∞ icoder-plus-backend (—ç—Ç–æ–≥–æ serverless):

OPENAI_API_KEY ‚Äî –≤–∞—à –∫–ª—é—á OpenAI

(–ø–æ –∂–µ–ª–∞–Ω–∏—é) NODE_ENV=production

(–ê–Ω—Ç—Ä–æ–ø–∏–∫ –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ø–æ–∑–∂–µ, –≤ —ç—Ç–æ–º –º–∏–Ω–∏–º—É–º–µ –æ–Ω –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è.)

‚ñ∂Ô∏è –õ–æ–∫–∞–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫ –∏ –¥–µ–ø–ª–æ–π
cd backend
# –ª–æ–∫–∞–ª—å–Ω–æ (—á–µ—Ä–µ–∑ vercel dev)
npm run dev

# –∑–∞—Ç–µ–º –¥–µ–ø–ª–æ–π
npm run deploy


–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Å–ª–µ –¥–µ–ø–ª–æ—è:

GET /api/health

POST /api/ai/analyze { analysisType, code, oldCode?, fileName? }

POST /api/ai/chat { message, code?, fileName? }

POST /api/ai/fix/apply { code, fileName? }